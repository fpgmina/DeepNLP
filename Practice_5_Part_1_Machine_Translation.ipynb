{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fpgmina/DeepNLP/blob/main/Practice_5_Part_1_Machine_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vOEr39Bst_5"
      },
      "source": [
        "# **Deep Natural Language Processing @ PoliTO**\n",
        "\n",
        "\n",
        "---\n",
        "**Teaching Assistant:** Ali Yassine\n",
        "\n",
        "**Credits:** Moreno La Quatra\n",
        "\n",
        "**Practice 5:** Machine Translation - Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9F11ek-0L8g"
      },
      "source": [
        "## **Machine Translation**\n",
        "\n",
        "Machine Translation is a sub-field of Natural Language Processing that aims at translating a text from a source language to a target language. In this practice, we will experiment with a Transformer-based model for Machine Translation. Specifically, we will benchmark the performance of a pre-trained MT model on Italian-English and English-Italian translation tasks.\n",
        "\n",
        "![](https://www.deepl.com/img/press/desktop_ENIT_2020-01.png)\n",
        "\n",
        "In this practice we will use a data collection provided by [tatoeba](https://tatoeba.org/). The following cell download a subset of the data collection, containing parallel Italian-English sentences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41mtAy092sCC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P6/train_it_en.tsv\n",
        "!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P6/test_it_en.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsCTUyoq2rZo"
      },
      "source": [
        "### **Question 1: Parsing data**\n",
        "\n",
        "The first step is to parse the data collection to generate a list of sentence pairs. The data are provided in `tsv` format, where each line contains a sentence pair in the following format:\n",
        "\n",
        "`<source_language_sentence>\\t<target_language_sentence>\\n`\n",
        "\n",
        "You are provided with a training and a test set. For this question you should parse both data splits and store them in your preferred data structure.\n",
        "\n",
        "**Note:** store train and test set into separate data objects."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "zLzi5cjdIgAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyW-AESi3yYe"
      },
      "source": [
        "### **Question 2: Pre-trained MT models**\n",
        "\n",
        "Pre-trained MT models are released to the public to allow researchers to experiment with them. In this question you will load a pre-trained MT model and use it to translate sentences from Italian to English and vice-versa.\n",
        "\n",
        "[EasyNMT](https://github.com/UKPLab/EasyNMT) is a Python library that provides an easy-to-use interface to pre-trained MT models. It provides a simple wrapper over HuggingFace transformers library for machine translation. In this question you will use EasyNMT to load a pre-trained MT model and translate sentences from Italian to English and vice-versa:\n",
        "\n",
        "- Load the pre-trained model for a specific direction (e.g., Italian-English or English-Italian)\n",
        "- Translate all the sentences in the test set from the source language to the target language.\n",
        "\n",
        "\n",
        "**Note 1**: the choice for the MT model is up to you.\n",
        "\n",
        "**Note 2**: store the translated sentences in both directions using the data structure of your choice."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install easynmt sacremoses"
      ],
      "metadata": {
        "id": "vrSfg-lyIv6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "SvTAPXNEIxXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv-4koeH6yvt"
      },
      "source": [
        "### **Question 3: BLEU and METEOR scores**\n",
        "\n",
        "In this question you will evaluate the performance of your machine translation (MT) model using **two** evaluation metrics: **[BLEU evaluation metric](https://github.com/mjpost/sacrebleu)** and **[METEOR evaluation metric](https://huggingface.co/spaces/evaluate-metric/meteor)**. You **must** compute and report scores for both translation directions: `EN→IT` and `IT→EN`.\n",
        "\n",
        "---\n",
        "\n",
        "#### BLEU (Bilingual Evaluation Understudy)\n",
        "\n",
        "**BLEU** measures how much the model’s translation overlaps with a reference translation by comparing shared **n-grams** (word sequences). It gives a precision-oriented score that rewards exact word matches.\n",
        "\n",
        "- **Pros:** Fast, standardized, and good for large-scale comparisons.\n",
        "- **Cons:** Only captures exact matches, ignoring synonyms or paraphrases; may not always align with human judgment.\n",
        "\n",
        "> Use BLEU as implemented in `sacrebleu`.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### METEOR (Metric for Evaluation of Translation with Explicit ORdering)\n",
        "\n",
        "**METEOR** was developed to better reflect human judgment by allowing more flexible word matching. It aligns hypothesis and reference words using:\n",
        "\n",
        "- **Exact matches**\n",
        "- **Stem matches** (e.g., *run* ↔ *running*)\n",
        "- **Synonyms and paraphrases**\n",
        "\n",
        "It then combines these matches into a single score with penalties for disordered or fragmented output.\n",
        "\n",
        "- **Pros:** More linguistically aware; correlates better with human evaluations.\n",
        "- **Cons:** Slower to compute; depends on external lexical resources.\n",
        "\n",
        "> Compute METEOR using `evaluate` or `nltk`.\n",
        "\n",
        "---\n",
        "\n",
        "The following cell installs the `sacrebleu`, `nltk`, and `evaluate` libraries that can be used to compute these metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9dLMLRw7SDu"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install sacrebleu evaluate nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "srGLkpLoJOxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question 4: Comparison with another Pre-trained MT Model**\n",
        "\n",
        "In this question, you will experiment with another pre-trained MT model and compare its performance with the model used in Question 2.\n",
        "\n",
        "Follow the same translation procedure as before (EN→IT and IT→EN) and evaluate the results using the BLEU and METEOR metrics from Question 3.\n",
        "\n",
        "Use [EasyNMT](https://github.com/UKPLab/EasyNMT) to load and run the pre-trained model.\n"
      ],
      "metadata": {
        "id": "VoR_OKc5ghQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "HSmLo9KcrF9j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "a88d8d275dc8276b143b02757b297c7b7ccc4199bd118b2f9ce33906ca7c97c0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}